{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20638 files belonging to 15 classes.\n",
      "Using 16511 files for training.\n",
      "Using 4127 files for validation.\n"
     ]
    }
   ],
   "source": [
    "training_data,validation_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    'PlantVillage',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128,128),\n",
    "    shuffle=True,\n",
    "    seed=27,\n",
    "    validation_split= 0.2,\n",
    "    subset='both',\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[115.   107.   130.  ]\n",
      "   [117.5  109.5  132.5 ]\n",
      "   [120.   112.   135.  ]\n",
      "   ...\n",
      "   [126.25 118.25 142.25]\n",
      "   [120.   112.   136.  ]\n",
      "   [117.25 109.25 133.25]]\n",
      "\n",
      "  [[117.25 109.25 132.25]\n",
      "   [119.25 111.25 134.25]\n",
      "   [121.   113.   136.  ]\n",
      "   ...\n",
      "   [126.   118.   142.  ]\n",
      "   [122.75 114.75 138.75]\n",
      "   [125.25 117.25 141.25]]\n",
      "\n",
      "  [[111.5  103.5  126.5 ]\n",
      "   [114.25 106.25 129.25]\n",
      "   [122.25 114.25 137.25]\n",
      "   ...\n",
      "   [122.25 114.25 138.25]\n",
      "   [122.75 114.75 138.75]\n",
      "   [128.5  120.5  144.5 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[100.75  92.75 113.75]\n",
      "   [ 97.    89.   110.  ]\n",
      "   [ 93.    85.   106.  ]\n",
      "   ...\n",
      "   [ 92.5   84.5  107.5 ]\n",
      "   [ 94.5   86.5  109.5 ]\n",
      "   [ 96.    88.   111.  ]]\n",
      "\n",
      "  [[ 97.5   89.5  110.5 ]\n",
      "   [ 93.5   85.5  106.5 ]\n",
      "   [ 99.25  91.25 112.25]\n",
      "   ...\n",
      "   [ 92.25  84.25 107.25]\n",
      "   [ 97.25  89.25 112.25]\n",
      "   [ 91.    83.   106.  ]]\n",
      "\n",
      "  [[ 99.5   91.5  112.5 ]\n",
      "   [108.5  100.5  121.5 ]\n",
      "   [104.75  96.75 117.75]\n",
      "   ...\n",
      "   [ 93.25  85.25 108.25]\n",
      "   [100.25  92.25 115.25]\n",
      "   [ 96.25  88.25 111.25]]]\n",
      "\n",
      "\n",
      " [[[196.   194.   205.  ]\n",
      "   [192.75 190.75 201.75]\n",
      "   [193.25 191.25 202.25]\n",
      "   ...\n",
      "   [193.75 195.75 207.75]\n",
      "   [192.25 194.25 206.25]\n",
      "   [189.5  191.5  203.5 ]]\n",
      "\n",
      "  [[195.   193.   204.  ]\n",
      "   [195.75 193.75 204.75]\n",
      "   [196.75 194.75 205.75]\n",
      "   ...\n",
      "   [193.25 195.25 207.25]\n",
      "   [190.75 192.75 204.75]\n",
      "   [187.75 189.75 201.75]]\n",
      "\n",
      "  [[197.5  195.5  206.5 ]\n",
      "   [198.75 196.75 207.75]\n",
      "   [200.5  198.5  209.5 ]\n",
      "   ...\n",
      "   [193.   195.   207.  ]\n",
      "   [192.5  194.5  206.5 ]\n",
      "   [190.75 192.75 204.75]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[129.25 125.25 139.25]\n",
      "   [133.25 129.25 143.25]\n",
      "   [125.75 121.75 135.75]\n",
      "   ...\n",
      "   [141.75 138.75 149.75]\n",
      "   [145.   142.   153.  ]\n",
      "   [138.25 135.25 146.25]]\n",
      "\n",
      "  [[124.5  120.5  134.5 ]\n",
      "   [128.25 124.25 138.25]\n",
      "   [130.   126.   140.  ]\n",
      "   ...\n",
      "   [133.5  130.5  141.5 ]\n",
      "   [138.   135.   146.  ]\n",
      "   [138.5  135.5  146.5 ]]\n",
      "\n",
      "  [[126.75 122.75 136.75]\n",
      "   [122.   118.   132.  ]\n",
      "   [126.5  122.5  136.5 ]\n",
      "   ...\n",
      "   [135.   132.   143.  ]\n",
      "   [138.25 135.25 146.25]\n",
      "   [139.5  136.5  147.5 ]]]\n",
      "\n",
      "\n",
      " [[[142.   133.   138.  ]\n",
      "   [142.5  133.5  138.5 ]\n",
      "   [164.25 155.25 160.25]\n",
      "   ...\n",
      "   [125.   115.   114.  ]\n",
      "   [137.75 127.75 126.75]\n",
      "   [115.   105.   104.  ]]\n",
      "\n",
      "  [[147.5  138.5  143.5 ]\n",
      "   [141.5  132.5  137.5 ]\n",
      "   [128.25 119.25 124.25]\n",
      "   ...\n",
      "   [128.25 118.25 117.25]\n",
      "   [131.5  121.5  120.5 ]\n",
      "   [140.   130.   129.  ]]\n",
      "\n",
      "  [[152.75 143.75 148.75]\n",
      "   [164.   155.   160.  ]\n",
      "   [192.   183.   188.  ]\n",
      "   ...\n",
      "   [130.5  120.5  119.5 ]\n",
      "   [127.   117.   116.  ]\n",
      "   [144.   134.   133.  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[165.75 160.75 164.75]\n",
      "   [169.25 164.25 168.25]\n",
      "   [169.25 164.25 168.25]\n",
      "   ...\n",
      "   [156.5  150.5  152.5 ]\n",
      "   [156.5  150.5  152.5 ]\n",
      "   [153.5  147.5  149.5 ]]\n",
      "\n",
      "  [[169.5  164.5  168.5 ]\n",
      "   [168.5  163.5  167.5 ]\n",
      "   [165.   160.   164.  ]\n",
      "   ...\n",
      "   [151.25 145.25 147.25]\n",
      "   [154.   148.   150.  ]\n",
      "   [152.75 146.75 148.75]]\n",
      "\n",
      "  [[167.25 162.25 166.25]\n",
      "   [166.   161.   165.  ]\n",
      "   [164.25 159.25 163.25]\n",
      "   ...\n",
      "   [155.   149.   151.  ]\n",
      "   [155.75 149.75 151.75]\n",
      "   [153.   147.   149.  ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[197.5  188.5  193.5 ]\n",
      "   [190.   181.   186.  ]\n",
      "   [189.5  180.5  185.5 ]\n",
      "   ...\n",
      "   [199.   194.   198.  ]\n",
      "   [196.5  191.5  195.5 ]\n",
      "   [206.75 201.75 205.75]]\n",
      "\n",
      "  [[199.75 190.75 195.75]\n",
      "   [194.   185.   190.  ]\n",
      "   [206.5  197.5  202.5 ]\n",
      "   ...\n",
      "   [206.25 201.25 205.25]\n",
      "   [196.75 191.75 195.75]\n",
      "   [191.75 186.75 190.75]]\n",
      "\n",
      "  [[188.5  179.5  184.5 ]\n",
      "   [195.   186.   191.  ]\n",
      "   [198.75 189.75 194.75]\n",
      "   ...\n",
      "   [192.25 187.25 191.25]\n",
      "   [183.   178.   182.  ]\n",
      "   [207.5  203.   206.75]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[156.   145.   151.  ]\n",
      "   [148.5  137.5  143.5 ]\n",
      "   [150.   139.   145.  ]\n",
      "   ...\n",
      "   [142.25 133.25 138.25]\n",
      "   [161.25 152.25 157.25]\n",
      "   [163.25 154.25 159.25]]\n",
      "\n",
      "  [[155.75 144.75 150.75]\n",
      "   [134.75 123.75 129.75]\n",
      "   [156.   145.   151.  ]\n",
      "   ...\n",
      "   [149.75 140.75 145.75]\n",
      "   [153.5  144.5  149.5 ]\n",
      "   [157.   148.   153.  ]]\n",
      "\n",
      "  [[143.75 132.75 138.75]\n",
      "   [153.25 142.25 148.25]\n",
      "   [147.5  136.5  142.5 ]\n",
      "   ...\n",
      "   [135.75 126.75 131.75]\n",
      "   [144.   135.   140.  ]\n",
      "   [152.25 143.25 148.25]]]\n",
      "\n",
      "\n",
      " [[[106.   104.   115.  ]\n",
      "   [ 96.75  94.75 105.75]\n",
      "   [ 99.    97.   108.  ]\n",
      "   ...\n",
      "   [136.25 138.25 151.25]\n",
      "   [141.   143.   156.  ]\n",
      "   [139.75 141.75 154.75]]\n",
      "\n",
      "  [[123.25 121.25 132.25]\n",
      "   [116.25 114.25 125.25]\n",
      "   [111.25 109.25 120.25]\n",
      "   ...\n",
      "   [133.75 135.75 148.75]\n",
      "   [136.   138.   151.  ]\n",
      "   [136.25 138.25 151.25]]\n",
      "\n",
      "  [[ 92.75  90.75 101.75]\n",
      "   [ 99.5   97.5  108.5 ]\n",
      "   [116.   114.   125.  ]\n",
      "   ...\n",
      "   [130.5  132.5  145.5 ]\n",
      "   [131.25 133.25 146.25]\n",
      "   [130.   132.   145.  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[123.25 121.25 134.25]\n",
      "   [129.25 127.25 140.25]\n",
      "   [137.75 135.75 148.75]\n",
      "   ...\n",
      "   [173.5  175.5  187.5 ]\n",
      "   [181.   183.   195.  ]\n",
      "   [172.   174.   186.  ]]\n",
      "\n",
      "  [[112.5  110.5  123.5 ]\n",
      "   [142.   140.   153.  ]\n",
      "   [118.   116.   129.  ]\n",
      "   ...\n",
      "   [175.   177.   189.  ]\n",
      "   [184.25 186.25 198.25]\n",
      "   [181.25 183.25 195.25]]\n",
      "\n",
      "  [[130.   128.   141.  ]\n",
      "   [113.   111.   124.  ]\n",
      "   [147.   145.   158.  ]\n",
      "   ...\n",
      "   [173.5  175.5  187.5 ]\n",
      "   [179.5  181.5  193.5 ]\n",
      "   [187.   189.   201.  ]]]\n",
      "\n",
      "\n",
      " [[[202.   193.   184.  ]\n",
      "   [198.25 189.25 180.25]\n",
      "   [188.75 179.75 170.75]\n",
      "   ...\n",
      "   [181.25 171.25 161.25]\n",
      "   [171.5  161.5  151.5 ]\n",
      "   [175.5  165.5  155.5 ]]\n",
      "\n",
      "  [[197.5  188.5  179.5 ]\n",
      "   [196.75 187.75 178.75]\n",
      "   [188.25 179.25 170.25]\n",
      "   ...\n",
      "   [182.25 172.25 162.25]\n",
      "   [176.25 166.25 156.25]\n",
      "   [176.75 166.75 156.75]]\n",
      "\n",
      "  [[203.25 194.25 185.25]\n",
      "   [199.   190.   181.  ]\n",
      "   [195.5  186.5  177.5 ]\n",
      "   ...\n",
      "   [173.75 163.75 153.75]\n",
      "   [173.75 163.75 153.75]\n",
      "   [170.75 160.75 150.75]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[142.75 117.75 110.75]\n",
      "   [128.   103.    96.  ]\n",
      "   [136.   111.   104.  ]\n",
      "   ...\n",
      "   [141.5  121.5  112.5 ]\n",
      "   [136.75 116.75 107.75]\n",
      "   [134.75 114.75 105.75]]\n",
      "\n",
      "  [[127.25 102.25  95.25]\n",
      "   [127.5  102.5   95.5 ]\n",
      "   [139.   114.   107.  ]\n",
      "   ...\n",
      "   [123.75 103.75  94.75]\n",
      "   [134.   114.   105.  ]\n",
      "   [132.25 112.25 103.25]]\n",
      "\n",
      "  [[128.75 103.75  96.75]\n",
      "   [137.25 112.25 105.25]\n",
      "   [140.75 115.75 108.75]\n",
      "   ...\n",
      "   [130.25 110.25 101.25]\n",
      "   [140.75 120.75 111.75]\n",
      "   [135.   115.   106.  ]]]], shape=(32, 128, 128, 3), dtype=float32) (32, 128, 128, 3)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]], shape=(32, 15), dtype=float32) (32, 15)\n"
     ]
    }
   ],
   "source": [
    "for x,y in training_data:\n",
    "    print(x, x.shape)\n",
    "    print(y, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=3, padding='same', activation='relu', input_shape=(128,128,3) ))\n",
    "model.add(Conv2D(filters=32,kernel_size=3, activation='relu',  ))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=64,kernel_size=3, padding='same', activation='relu' ))\n",
    "model.add(Conv2D(filters=64,kernel_size=3, activation='relu',  ))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=128,kernel_size=3, padding='same', activation='relu' ))\n",
    "model.add(Conv2D(filters=128,kernel_size=3, activation='relu',  ))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=256,kernel_size=3, padding='same', activation='relu',  ))\n",
    "model.add(Conv2D(filters=256,kernel_size=3, activation='relu',  ))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=512,kernel_size=3, padding='same', activation='relu' ))\n",
    "model.add(Conv2D(filters=512,kernel_size=3, activation='relu',  ))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1500, activation ='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=15, activation='softmax',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 126, 126, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 63, 63, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 63, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 30, 30, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 14, 14, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 2, 2, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1500)              3073500   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 15)                22515     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7808239 (29.79 MB)\n",
      "Trainable params: 7808239 (29.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516/516 [==============================] - 2465s 5s/step - loss: 1.4389 - accuracy: 0.5352 - val_loss: 0.6742 - val_accuracy: 0.7621\n",
      "Epoch 2/10\n",
      "516/516 [==============================] - 2216s 4s/step - loss: 0.6881 - accuracy: 0.7689 - val_loss: 0.6236 - val_accuracy: 0.7819\n",
      "Epoch 3/10\n",
      "204/516 [==========>...................] - ETA: 20:31 - loss: 0.4794 - accuracy: 0.8392"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(x=training_data, validation_data=validation_data, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving Model\n",
    "\n",
    "model.save(\"trained_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Recording History\n",
    "\n",
    "import json\n",
    "with open('training_hist.json', 'w') as f:\n",
    "    json.dump(training_history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation on training set\n",
    "\n",
    "train_loss, train_acc = model.evaluate(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation on training set\n",
    "\n",
    "val_loss, val_acc = model.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit(x=training_data, validation_data=validation_data, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(1,11)]\n",
    "plt.plot(epochs, training_history.history['accuracy'], color='red', label='Training accuracy')\n",
    "plt.plot(epochs, training_history.history['val_accuracy'], color='blue', label='Training accuracy')\n",
    "plt.xlabel('No of Epochs')\n",
    "plt.ylabel('Accuracy result')\n",
    "plt.title('visualization of Accuracy Result')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
